import numpy as np
import pandas as pd
import scipy.stats as stats
from typing import List, Dict, Tuple

from phenox.paths import PhenoXPaths


class BatchEffect:
    def __init__(self, clusters: Dict) -> None:
        """
        Initialize class
        :param clusters: key=cluster_ids, value=list of gds_ids
        """
        self.paths = PhenoXPaths()
        self.clusters = clusters
        self.num_clusters = len(clusters)
    
    # #from geneName.py -> to be sent to geo_data.py
    # def meta_from_gds(self, gds_list: list) -> Dict:
    #     """
    #     Get meta information, such as gds submission time, n_samples, platform from gds.
    #     gds_list is from gdsdict.keys()
    #     - This can replace the get_pubmed_ids()
    #     concerns:
    #     >> do not know how to get rid of the IntergerElement
    #     >> now the publication time is in seconds, we can convert to days or years?
    #     """
    #     qout = Entrez.read(Entrez.esummary(db="gds", id=",".join(gds_list)))
    #     return {sm['Id']:[sm['n_samples'],sm['PubMedIds'],sm['GPL'],datetime.strptime(sm['PDAT'],'%Y/%m/%d').timestamp()] for sm in qout}

    # For chi-squared test of platform types different from overall

    def _total_stats(self, meta_dict: Dict) -> List:
        """
        Generate total distributions for each gds metadata value
        :param meta_dict: key=gds_ids, value=list of gds metrics (n_samples,
            pmids, GPLs, dates)
        :return total_stats: list of lists (distributions of all gds for each
            set: n_samples, pmids, GPLs, dates)
        """
        total_stats = [[] for i in range(4)]
        [[total_stats[i].append(meta_dict[gds][i]) for gds in meta_dict] for i in range(4)]
        return total_stats

    def _generate_ks_test(self, meta_dict: Dict, total_dist: List, clust_stats=None) -> Dict:
        """
        Kolmogrov-Smirnov test for cluster vals and total vals from same dist
        :param meta_dict: generated by meta_from_gds
        :param clust_stats: pass mutable dict for recursive additions
            key=cluster_ids, value=list of tuples(test_parameter, KS-stat,
                                                  p-value, mean, s.d.)
        :return:
        """
        if clust_stats is None:
            clust_stats = {}
        
        
        
        for cluster in self.clusters:
            clust_frame = pd.DataFrame()
            ####do something to count categories for platform
            KS_stat, p_val = stats.ks_2samp(, f_exp=overall_count)
            clust_stats[cluster] = {'GPL': [chi_sq, p_val]}
            if p_val <= 0.05:
                print('{} is significantly different from overall platform distribution'.format(cluster))
        return
    
    def cluster_stats(self):
        """
        Run pipeline
        :return:
        """
        total_stats = self._total_stats(meta_dict)
        clust_stats = [self._generate_ks_test(meta_dict, total_stats[i], clust_stats) for i in [0, 3]]
        